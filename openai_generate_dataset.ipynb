{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f1b0d5",
   "metadata": {},
   "source": [
    "# ELI5 Dataset - ChatGPT Answer Generation\n",
    "\n",
    "This notebook processes the ELI5 (Explain Like I'm 5) dataset and generates LLM answers using OpenAI's ChatGPT.\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: HuggingFace dataset `rexarski/eli5_category`\n",
    "- **Period**: January 2017 - June 2021\n",
    "- **Content**: Human-written questions and answers from the ELI5 subreddit\n",
    "- **Purpose**: Generate one LLM answer per unique question and merge with human responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e67a35",
   "metadata": {},
   "source": [
    "####  **<span style=\"color:red\">IMPORTANT: <span>**\n",
    "\n",
    "**Workflow & Integration:**\n",
    "1. This notebook: Load dataset → Test API → Generate ChatGPT answers → Merge with human answers\n",
    "2. Model: gpt-4o-mini\n",
    "3. Each unique question gets ONE LLM answer replicated across all human responses\n",
    "4. **To combine with Gemini:**\n",
    "   - Run this notebook first (generates human + chatgpt answers)\n",
    "   - Run `gemini_generate_dataset_clean.ipynb` (generates gemini answers)\n",
    "   - Use the merge function in Cell 10 to combine both without duplicating human answers\n",
    "   - Final dataset: human + chatgpt + gemini sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e78e1",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b884cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install pandas numpy datasets\n",
    "# !pip install openai\n",
    "# !pip install gdown matplotlib seaborn tqdm\n",
    "# !pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# OpenAI API\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1093da",
   "metadata": {},
   "source": [
    "## 2. Set Up OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"✓ OpenAI API key configured successfully\")\n",
    "else:\n",
    "    print(\"✗ Warning: OpenAI API key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97910b0a",
   "metadata": {},
   "source": [
    "## 3. Load the ELI5 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0214ab",
   "metadata": {},
   "source": [
    "## Configuration - Set Parameters Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions_to_generate = 10\n",
    "delay_between_api_calls = 1\n",
    "test_sample_size = 2\n",
    "\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Questions to generate: {num_questions_to_generate}\")\n",
    "print(f\"  Delay between calls: {delay_between_api_calls}s\")\n",
    "print(f\"  Test sample size: {test_sample_size}\")\n",
    "print(f\"  Model: {openai_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ea40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./human_data/output/eli5_sample.csv\"\n",
    "\n",
    "df_human = pd.read_csv(path)\n",
    "print(f\"✓ Dataset loaded with {len(df_human)} records\")\n",
    "\n",
    "# Get unique questions\n",
    "unique_questions = df_human[['q_id', 'title']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"✓ Found {len(unique_questions)} unique questions\")\n",
    "print(f\"  Average answers per question: {len(df_human) / len(unique_questions):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8631d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of dataset:\")\n",
    "print(\"=\" * 80)\n",
    "df_human[['q_id', 'title', 'text']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185b30",
   "metadata": {},
   "source": [
    "## 4. Define LLM Answer Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chatgpt_answer(question, model=\"gpt-4o-mini\", max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate an ELI5-style answer using ChatGPT.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        model: OpenAI model to use (default: gpt-4o-mini)\n",
    "        max_retries: Number of retry attempts on failure\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer as string, or error message if failed\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        return \"ERROR: OpenAI API key not configured\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are answering questions in the style of the ELI5 (Explain Like I'm 5) subreddit. \n",
    "Provide a clear, simple explanation that a 5-year-old could understand, but still be informative.\n",
    "Keep everything as one block of text.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"Question: {question}\\n\\nAnswer:\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000,\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Attempt {attempt + 1} failed: {str(e)[:100]}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                return f\"ERROR: {str(e)}\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058ec9c",
   "metadata": {},
   "source": [
    "## 5. Test API with Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample questions\n",
    "print(f\"Testing API with {test_sample_size} sample questions...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_questions = unique_questions.head(test_sample_size)\n",
    "\n",
    "for idx, row in test_questions.iterrows():\n",
    "    question = row['title']\n",
    "    print(f\"\\n[Test {idx + 1}] {question[:70]}...\")\n",
    "    answer = generate_chatgpt_answer(question)\n",
    "    \n",
    "    if answer.startswith(\"ERROR\"):\n",
    "        print(f\"✗ {answer}\")\n",
    "    else:\n",
    "        print(f\"✓ Generated ({len(answer)} chars): {answer[:100]}...\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"API test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2fb95",
   "metadata": {},
   "source": [
    "## 6. Generate LLM Answer for Each Unique Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one LLM answer per unique question\n",
    "llm_answers_map = {}  # Map from q_id to llm_answer\n",
    "\n",
    "questions_to_process = unique_questions.head(min(num_questions_to_generate, len(unique_questions)))\n",
    "print(f\"Generating {len(questions_to_process)} LLM answers...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with tqdm(total=len(questions_to_process), desc=\"Generating answers\") as pbar:\n",
    "    for idx, row in questions_to_process.iterrows():\n",
    "        q_id = row['q_id']\n",
    "        question = row['title']\n",
    "        \n",
    "        llm_answer = generate_chatgpt_answer(question)\n",
    "        \n",
    "        if not llm_answer.startswith(\"ERROR\"):\n",
    "            llm_answers_map[q_id] = llm_answer\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            print(f\"\\n✗ Skipped {q_id}: {llm_answer[:80]}\")\n",
    "        \n",
    "        time.sleep(delay_between_api_calls)\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"✓ Successfully generated {len(llm_answers_map)} / {len(questions_to_process)} LLM answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d594c63",
   "metadata": {},
   "source": [
    "## 7. Combine Human and LLM Answers with Source Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create human answers dataset with source column\n",
    "df_human_labeled = df_human.copy()\n",
    "df_human_labeled['source'] = 'human'\n",
    "\n",
    "# Create LLM answers dataset from the map\n",
    "# Get one row per unique question from the original data\n",
    "unique_rows = df_human.drop_duplicates(subset=['q_id'])[['q_id', 'title']].reset_index(drop=True)\n",
    "\n",
    "# Filter to only questions that have LLM answers\n",
    "llm_rows_list = []\n",
    "for q_id, llm_answer in llm_answers_map.items():\n",
    "    # Get the first row for this q_id to use as template\n",
    "    template_row = df_human[df_human['q_id'] == q_id].iloc[0].copy()\n",
    "    template_row['text'] = llm_answer\n",
    "    template_row['source'] = 'chatgpt'\n",
    "    llm_rows_list.append(template_row)\n",
    "\n",
    "df_llm_labeled = pd.DataFrame(llm_rows_list).reset_index(drop=True)\n",
    "\n",
    "# Combine human and LLM answers\n",
    "df_combined = pd.concat([df_human_labeled, df_llm_labeled], ignore_index=True)\n",
    "\n",
    "# Shuffle for better mixing\n",
    "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Combined dataset summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total rows: {len(df_combined)}\")\n",
    "print(f\"Human answers: {(df_combined['source'] == 'human').sum()}\")\n",
    "print(f\"ChatGPT answers: {(df_combined['source'] == 'chatgpt').sum()}\")\n",
    "print(f\"Columns: {list(df_combined.columns)}\")\n",
    "print(f\"\\nDataset shape: {df_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77fa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample rows\n",
    "print(\"\\nSample rows from combined dataset:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for source_type in ['human', 'chatgpt']:\n",
    "    sample = df_combined[df_combined['source'] == source_type][['q_id', 'title', 'text', 'source']].head(1)\n",
    "    if not sample.empty:\n",
    "        row = sample.iloc[0]\n",
    "        print(f\"\\n{source_type.upper()}:\")\n",
    "        print(f\"  Question: {row['title'][:60]}\")\n",
    "        print(f\"  Answer: {row['text'][:80]}...\")\n",
    "        print(f\"  Source: {row['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00494fa2",
   "metadata": {},
   "source": [
    "## 8. Save Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "output_folder = \"openai-output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = os.path.join(output_folder, f\"eli5_combined_dataset_{timestamp}.csv\")\n",
    "df_combined.to_csv(csv_filename, index=False)\n",
    "print(f\"✓ CSV saved to: {csv_filename}\")\n",
    "\n",
    "# Save as Parquet\n",
    "parquet_filename = os.path.join(output_folder, f\"eli5_combined_dataset_{timestamp}.parquet\")\n",
    "df_combined.to_parquet(parquet_filename, index=False)\n",
    "print(f\"✓ Parquet saved to: {parquet_filename}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'timestamp': timestamp,\n",
    "    'total_rows': len(df_combined),\n",
    "    'unique_questions': len(unique_questions),\n",
    "    # Add int() wrapper around these sums\n",
    "    'human_answers': int((df_combined['source'] == 'human').sum()),\n",
    "    'chatgpt_answers': int((df_combined['source'] == 'chatgpt').sum()),\n",
    "    'llm_model': 'gpt-4o-mini',\n",
    "    'columns': list(df_combined.columns)\n",
    "}\n",
    "\n",
    "metadata_filename = os.path.join(output_folder, f\"metadata_{timestamp}.json\")\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"✓ Metadata saved to: {metadata_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET GENERATION COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
